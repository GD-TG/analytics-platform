# Настройка AI модели для анализа данных

## Выбранная модель

Для анализа данных и формирования отчетов используется модель **T5-small** от Hugging Face:
- Размер: ~240MB
- Требования к RAM: ~1-2GB
- Подходит для текстового анализа и генерации отчетов

## Варианты использования

### Вариант 1: Hugging Face Inference API (рекомендуется для начала)

1. **Получите API ключ:**
   - Зарегистрируйтесь на https://huggingface.co
   - Создайте API токен в настройках профиля

2. **Добавьте в .env:**
   ```env
   HUGGINGFACE_API_KEY=your_api_key_here
   ```

3. **Готово!** Модель будет использоваться через API.

### Вариант 2: Локальная установка (для продакшена)

Для использования локальной модели установите Python и библиотеки:

```bash
pip install transformers torch
```

Затем создайте Python скрипт для обработки запросов (опционально).

## Альтернативные модели

Если нужна более мощная модель (до 8GB RAM):
- **T5-base** (~850MB) - более качественный анализ
- **GPT-2** (~500MB-1.5GB) - хорошая генерация текста
- **DistilBERT** (~250MB) - быстрый анализ

## Использование

AI анализ автоматически вызывается при запросе отчетов через API:
```
GET /api/ai/analyze/{project_id}?period=M
```

Анализ также интегрирован в основной процесс генерации отчетов.

